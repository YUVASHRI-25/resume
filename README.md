# ğŸ“„ Resume Insight - AI-Powered Resume Analysis System

**Resume Insight** is a comprehensive AI-powered system that analyzes resumes and job descriptions using advanced NLP and LLMs. It extracts skills, evaluates ATS compatibility, generates personalized improvement suggestions, and compares resumes with job descriptions to find skill gaps and compute matching scores.

## ğŸŒŸ Key Features

### ğŸ¤– AI-Powered Analysis
- **Mistral 7B Integration**: Advanced LLM for personalized recommendations
- **RAG System**: Retrieval-Augmented Generation with Chroma DB
- **Semantic Analysis**: Sentence transformers for content understanding
- **Smart Recommendations**: Context-aware improvement suggestions

### ğŸ“Š Comprehensive Analysis
- **ATS Compatibility**: Automated scoring and optimization
- **Skills Matching**: Technical and soft skills detection
- **Keyword Optimization**: Role-specific keyword analysis
- **Section Analysis**: Complete resume structure evaluation
- **Grammar Check**: Language quality assessment

### ğŸ¯ Multi-Format Support
- **PDF Processing**: Advanced PDF text extraction with pdfplumber
- **DOCX Support**: Microsoft Word document parsing
- **OCR Capability**: Image-based resume processing with PaddleOCR
- **Text Processing**: Plain text file support

### ğŸš€ Modern Architecture
- **FastAPI Backend**: High-performance API server
- **Streamlit Frontend**: Interactive web interface
- **PostgreSQL Database**: Robust data persistence
- **Redis Caching**: Fast session management
- **Chroma DB**: Vector database for RAG system

## ğŸ“ Project Structure

```
resume_insight/
â”œâ”€â”€ app/                          # Main application directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # FastAPI main application
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”œâ”€â”€ database.py               # Database connection and models
â”‚   â””â”€â”€ api/                      # API endpoints
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ resume.py             # Resume analysis endpoints
â”‚       â”œâ”€â”€ llm.py                # LLM integration endpoints
â”‚       â””â”€â”€ rag.py                # RAG system endpoints
â”œâ”€â”€ core/                         # Core business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzer.py               # Main ResumeAnalyzer class
â”‚   â”œâ”€â”€ llm_service.py            # LLM service integration
â”‚   â””â”€â”€ rag_service.py            # RAG system implementation
â”œâ”€â”€ services/                     # External services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_processor.py         # File processing utilities
â”‚   â””â”€â”€ nlp_processor.py          # NLP processing utilities
â”œâ”€â”€ frontend/                     # Streamlit frontend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                    # Main Streamlit application
â”‚   â”œâ”€â”€ components/               # UI components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sidebar.py            # Sidebar component
â”‚   â””â”€â”€ utils/                    # Frontend utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ styling.py            # CSS and styling
â”‚       â””â”€â”€ helpers.py            # Helper functions
â”œâ”€â”€ utils/                        # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py              # Application constants
â”‚   â”œâ”€â”€ validators.py             # Input validation
â”‚   â””â”€â”€ formatters.py             # Data formatting utilities
â”œâ”€â”€ data/                         # Data files
â”‚   â”œâ”€â”€ uploads/                  # Uploaded files
â”‚   â”œâ”€â”€ chroma_db/                # Chroma DB storage
â”‚   â””â”€â”€ embeddings/               # Pre-computed embeddings
â”œâ”€â”€ tests/                        # Test files
â”œâ”€â”€ static/                       # Static files
â”œâ”€â”€ env.example                   # Environment variables template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py                      # Setup script
â”œâ”€â”€ run.py                        # Application entry point
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

1. **Clone the repository**
```bash
git clone <repository-url>
cd resume_insight
```

2. **Run the setup script**
```bash
python setup.py
```

3. **Start the application**
```bash
# Windows
start.bat

# Unix/Mac
./start.sh

# Manual
python run.py dev
```

### Option 2: Manual Setup

1. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Download spaCy model**
```bash
python -m spacy download en_core_web_sm
```

4. **Set up environment variables**
```bash
cp env.example .env
# Edit .env with your configuration
```

5. **Start the application**
```bash
python run.py dev
```

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file with the following variables:

```env
# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/resume_insight
REDIS_URL=redis://localhost:6379

# LLM API Keys (At least one required)
MISTRAL_API_KEY=your_mistral_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# AWS Configuration (Optional - for S3 storage)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_NAME=resume-insight-storage

# Application Configuration
SECRET_KEY=your_secret_key_here_change_this_in_production
DEBUG=True
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=["http://localhost:8501", "http://127.0.0.1:8501"]

# File Upload Configuration
MAX_FILE_SIZE=20971520  # 20MB in bytes
ALLOWED_EXTENSIONS=pdf,docx,txt,png,jpg,jpeg

# Chroma DB Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Required API Keys

You need at least one LLM API key:

- **Mistral API**: Get your API key from [Mistral AI](https://console.mistral.ai/)
- **OpenAI API**: Get your API key from [OpenAI](https://platform.openai.com/)

## ğŸ¯ Usage

### Access Points

After starting the application:

- **Frontend UI**: http://localhost:8501
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Interactive API**: http://localhost:8000/redoc

### Basic Workflow

1. **Upload Resume**: Upload your resume in PDF, DOCX, or TXT format
2. **Select Job Role**: Choose your target job role from the dropdown
3. **Get Analysis**: View comprehensive analysis results across multiple tabs
4. **AI Recommendations**: Get personalized suggestions from the AI assistant
5. **Download Report**: Generate and download a detailed PDF report

### API Endpoints

#### Resume Analysis
- `POST /api/resume/upload` - Upload resume file
- `POST /api/resume/analyze/{resume_id}` - Analyze uploaded resume
- `GET /api/resume/{resume_id}` - Get analysis results
- `POST /api/resume/compare` - Compare resume with job description

#### LLM Integration
- `POST /api/llm/recommendations` - Get AI recommendations
- `POST /api/llm/chat` - Interactive chat with AI assistant
- `POST /api/llm/skill-suggestions` - Get skill suggestions
- `POST /api/llm/ats-optimization` - Get ATS optimization tips

#### RAG System
- `POST /api/rag/similar-resumes` - Find similar resumes
- `POST /api/rag/context` - Get contextual recommendations
- `POST /api/rag/index-resume` - Add resume to RAG index

## ğŸ› ï¸ Development

### Running Individual Services

```bash
# Backend only
python run.py backend

# Frontend only
python run.py frontend

# Both services (development)
python run.py dev
```

### Code Quality

```bash
# Format code
black .

# Lint code
flake8 .

# Type checking
mypy .

# Run tests
pytest tests/
```

### Database Management

```bash
# Initialize database (if using PostgreSQL)
alembic upgrade head

# Create migration
alembic revision --autogenerate -m "Description"

# Apply migration
alembic upgrade head
```

## ğŸ“Š Analysis Features

### ATS Compatibility Scoring
- **Section Completeness**: Checks for essential sections
- **Formatting**: Evaluates bullet points, headers, and structure
- **Content Length**: Ensures appropriate word count
- **Contact Information**: Validates email and phone presence

### Skills Analysis
- **Technical Skills**: Detects programming languages, tools, frameworks
- **Soft Skills**: Identifies leadership, communication, teamwork skills
- **Role Matching**: Compares skills with job requirements
- **Missing Skills**: Suggests additional skills to add

### Keyword Optimization
- **Job-Specific Keywords**: Matches resume content with role requirements
- **Industry Terms**: Identifies relevant industry terminology
- **Skill Keywords**: Finds technical and soft skill mentions
- **Density Analysis**: Evaluates keyword distribution

### AI-Powered Recommendations
- **Personalized Suggestions**: Tailored advice based on analysis
- **Improvement Areas**: Identifies specific weaknesses
- **Action Items**: Provides prioritized improvement tasks
- **Best Practices**: Shares industry-standard recommendations

## ğŸ”§ Troubleshooting

### Common Issues

1. **Backend not starting**
   - Check if port 8000 is available
   - Verify database connection in `.env`
   - Ensure all dependencies are installed

2. **Frontend not loading**
   - Check if port 8501 is available
   - Verify backend is running
   - Check browser console for errors

3. **File upload fails**
   - Check file size (max 20MB)
   - Verify file format (PDF, DOCX, TXT)
   - Ensure upload directory exists

4. **AI features not working**
   - Verify API keys in `.env`
   - Check internet connection
   - Ensure API quotas are not exceeded

### System Requirements

- **Python**: 3.8 or higher
- **Memory**: 4GB RAM minimum, 8GB recommended
- **Storage**: 5GB free space minimum
- **OS**: Windows 10+, macOS 10.14+, or Linux

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Mistral AI** for providing the Mistral 7B model
- **OpenAI** for GPT model integration
- **Chroma DB** for vector database capabilities
- **Streamlit** for the frontend framework
- **FastAPI** for the backend framework

## ğŸ“ Support

For support, please:
1. Check the [troubleshooting section](#-troubleshooting)
2. Search existing [issues](https://github.com/your-repo/issues)
3. Create a new issue with detailed information

---

**Made with â¤ï¸ for better resumes and career success!**
